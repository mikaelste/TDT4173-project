{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Master import MasterDataframes, ModelTrainer\n",
    "\n",
    "\n",
    "# Data handling\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Types handling\n",
    "import numpy as np\n",
    "\n",
    "# Data science\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.feature_selection import SelectFromModel, RFECV\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, make_scorer\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures, DropConstantFeatures\n",
    "\n",
    "\n",
    "# Machine learning tool\n",
    "import xgboost as xgb\n",
    "# Optimization / feature engineering tools\n",
    "import optuna\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Smart options\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = MasterDataframes().prep_dataset_x_y(\"A\", drop_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-30 13:15:57,504] A new study created in memory with name: regression\n",
      "[I 2023-09-30 13:16:01,105] Trial 1 finished with value: 261.30172238437825 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.5886752298472008, 'n_estimators': 220, 'min_child_weight': 3, 'gamma': 0.6511788493066277, 'subsample': 0.75, 'colsample_bytree': 0.65, 'reg_alpha': 0.06299001856365276, 'reg_lambda': 0.18632148280412503, 'random_state': 940}. Best is trial 1 with value: 261.30172238437825.\n",
      "[I 2023-09-30 13:16:06,772] Trial 3 finished with value: 223.84076433020405 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.24705687394975925, 'n_estimators': 931, 'min_child_weight': 5, 'gamma': 0.816413296125129, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.7032252522593979, 'reg_lambda': 0.5989324072105601, 'random_state': 521}. Best is trial 3 with value: 223.84076433020405.\n",
      "[I 2023-09-30 13:16:07,492] Trial 6 finished with value: 309.0761389524976 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 3, 'learning_rate': 0.902154184878927, 'n_estimators': 659, 'min_child_weight': 7, 'gamma': 0.5130434696174643, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 0.5673580402606103, 'reg_lambda': 0.8578434004239375, 'random_state': 616}. Best is trial 3 with value: 223.84076433020405.\n",
      "[I 2023-09-30 13:16:09,209] Trial 2 finished with value: 243.29562038538535 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 9, 'learning_rate': 0.5991537283851021, 'n_estimators': 526, 'min_child_weight': 6, 'gamma': 0.7925331785691868, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.8468352798837926, 'reg_lambda': 0.567051556243424, 'random_state': 532}. Best is trial 3 with value: 223.84076433020405.\n",
      "[I 2023-09-30 13:16:09,763] Trial 8 finished with value: 228.57184929861418 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 3, 'learning_rate': 0.5206395247956616, 'n_estimators': 226, 'min_child_weight': 1, 'gamma': 0.5891240061940966, 'subsample': 1.0, 'colsample_bytree': 0.9, 'reg_alpha': 0.17716972948326665, 'reg_lambda': 0.8800738667202807, 'random_state': 763}. Best is trial 3 with value: 223.84076433020405.\n",
      "[I 2023-09-30 13:16:12,880] Trial 4 finished with value: 205.1823511522649 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 5, 'learning_rate': 0.18895448816549879, 'n_estimators': 969, 'min_child_weight': 8, 'gamma': 0.9466858931319445, 'subsample': 0.9, 'colsample_bytree': 0.85, 'reg_alpha': 0.01447912737810566, 'reg_lambda': 0.2365243104972173, 'random_state': 474}. Best is trial 4 with value: 205.1823511522649.\n",
      "[I 2023-09-30 13:16:15,244] Trial 5 finished with value: 321.02442936328003 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 9, 'learning_rate': 0.6943901776342644, 'n_estimators': 702, 'min_child_weight': 10, 'gamma': 0.9971308047739632, 'subsample': 0.6, 'colsample_bytree': 0.8, 'reg_alpha': 0.2522177076735575, 'reg_lambda': 0.47708937055288997, 'random_state': 28}. Best is trial 4 with value: 205.1823511522649.\n",
      "[I 2023-09-30 13:16:15,794] Trial 0 finished with value: 219.65392940903018 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.40786106636876174, 'n_estimators': 832, 'min_child_weight': 6, 'gamma': 0.27928083856179914, 'subsample': 0.85, 'colsample_bytree': 0.6, 'reg_alpha': 0.62238415023017, 'reg_lambda': 0.9701068392959877, 'random_state': 212}. Best is trial 4 with value: 205.1823511522649.\n",
      "[I 2023-09-30 13:16:17,039] Trial 7 finished with value: 244.25575080198718 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.6616144514003038, 'n_estimators': 721, 'min_child_weight': 7, 'gamma': 0.21857525480598317, 'subsample': 1.0, 'colsample_bytree': 0.8, 'reg_alpha': 0.11682294275327967, 'reg_lambda': 0.04161933139459873, 'random_state': 826}. Best is trial 4 with value: 205.1823511522649.\n",
      "[I 2023-09-30 13:16:21,040] Trial 9 finished with value: 193.52535243614156 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 9, 'learning_rate': 0.189872265357033, 'n_estimators': 709, 'min_child_weight': 3, 'gamma': 0.43970652378388386, 'subsample': 0.85, 'colsample_bytree': 0.85, 'reg_alpha': 0.3155256027531831, 'reg_lambda': 0.024472985747645594, 'random_state': 523}. Best is trial 9 with value: 193.52535243614156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graded! MAE:  193.52535243614156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=10, test_size=0.20)\n",
    "\n",
    "objective_list_reg = [\"reg:squarederror\"]\n",
    "tree_method = [\"approx\", \"hist\"]\n",
    "metric_list = [\"mae\"]\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", objective_list_reg),\n",
    "        \"eval_metric\": trial.suggest_categorical(\"eval_metric\", metric_list),\n",
    "        \"tree_method\": trial.suggest_categorical(\"tree_method\", tree_method),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),  # Adjust the range\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 1.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 1000),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),  # Increase the range\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.1, 1.0),  # Increase the lower bound\n",
    "        \"subsample\": trial.suggest_discrete_uniform(\"subsample\", 0.6, 1.0, 0.05),  # Reduce the range\n",
    "        \"colsample_bytree\": trial.suggest_discrete_uniform(\n",
    "            \"colsample_bytree\", 0.6, 1.0, 0.05\n",
    "        ),  # Reduce the range\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.01, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.01, 1.0),\n",
    "        \"random_state\": trial.suggest_int(\"random_state\", 1, 1000),\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"regression\")\n",
    "study.optimize(objective, n_trials=10, n_jobs=6)\n",
    "\n",
    "model = xgb.XGBRegressor(**study.best_params)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"graded! MAE: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.011258452, n=16, MAE: 199.5134638976881, Best: 193.52535243614156\n",
      "Thresh=0.011336514, n=15, MAE: 204.50074784170437, Best: 193.52535243614156\n",
      "Thresh=0.0121909045, n=14, MAE: 207.6331154631172, Best: 193.52535243614156\n",
      "Thresh=0.0130120935, n=13, MAE: 205.03324156038414, Best: 193.52535243614156\n",
      "Thresh=0.013582612, n=12, MAE: 209.55253885387592, Best: 193.52535243614156\n",
      "Thresh=0.0146718575, n=11, MAE: 222.00346962568662, Best: 193.52535243614156\n",
      "Thresh=0.015248544, n=10, MAE: 229.84831619234893, Best: 193.52535243614156\n",
      "Thresh=0.016560035, n=9, MAE: 238.06364985298603, Best: 193.52535243614156\n",
      "Thresh=0.018180085, n=8, MAE: 241.5697962951548, Best: 193.52535243614156\n",
      "Thresh=0.018819869, n=7, MAE: 244.48936988104126, Best: 193.52535243614156\n",
      "Thresh=0.01899978, n=6, MAE: 243.4444711440046, Best: 193.52535243614156\n",
      "Thresh=0.022283502, n=5, MAE: 246.25233251750342, Best: 193.52535243614156\n",
      "Thresh=0.02579325, n=4, MAE: 245.00379403394993, Best: 193.52535243614156\n",
      "Thresh=0.02656203, n=3, MAE: 276.12355264400156, Best: 193.52535243614156\n",
      "Thresh=0.13207836, n=2, MAE: 252.72947985801957, Best: 193.52535243614156\n",
      "Thresh=0.58996546, n=1, MAE: 284.99650050531625, Best: 193.52535243614156\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.sort(model.feature_importances_)\n",
    "best = accuracy\n",
    "for thresh in thresholds[int(len(thresholds)/5) : ]:\n",
    "    \n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    # train model\n",
    "    selection_model = xgb.XGBRegressor(**study.best_params)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    \n",
    "    accuracy = mean_absolute_error(y_test, y_pred)\n",
    "    if best > accuracy:\n",
    "        best = accuracy\n",
    "        print(f\"New best: {best}\")\n",
    "    print(f\"Thresh={str(thresh)}, n={select_X_train.shape[1]}, MAE: {accuracy}, Best: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n"
     ]
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=model, verbose=1, step=1, cv=KFold(5), scoring=make_scorer(mean_absolute_error))\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "X_train_selected_CV = rfecv.transform(X_train)\n",
    "X_test_selected_CV = rfecv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE score: 0.79\n",
      "Test MAE score: 0.79\n"
     ]
    }
   ],
   "source": [
    "rf_selected = xgb.XGBRegressor(**study.best_params)\n",
    "rf_selected.fit(X_train_selected_CV, y_train)\n",
    "\n",
    "print(f\"Train MAE score: {rf_selected.score(X_train_selected_CV, y_train):.2f}\")\n",
    "print(f\"Test MAE score: {rf_selected.score(X_test_selected_CV, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-09-30 13:09:02,804] A new study created in memory with name: regression\n",
      "[I 2023-09-30 13:09:03,718] Trial 0 finished with value: 223.1582632716738 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 3, 'learning_rate': 0.07559332505875452, 'n_estimators': 96, 'min_child_weight': 4, 'gamma': 0.15468354063481535, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 0.24018418337506595, 'reg_lambda': 0.1606536939781901, 'random_state': 358}. Best is trial 0 with value: 223.1582632716738.\n",
      "[I 2023-09-30 13:09:10,386] Trial 6 finished with value: 237.28175825278004 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 4, 'learning_rate': 0.40754522586537706, 'n_estimators': 528, 'min_child_weight': 7, 'gamma': 0.8816892093404158, 'subsample': 0.7, 'colsample_bytree': 0.65, 'reg_alpha': 0.9254798027618522, 'reg_lambda': 0.46185980190964643, 'random_state': 684}. Best is trial 0 with value: 223.1582632716738.\n",
      "[I 2023-09-30 13:09:11,875] Trial 4 finished with value: 265.9289023585374 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 6, 'learning_rate': 0.7562531002072433, 'n_estimators': 472, 'min_child_weight': 9, 'gamma': 0.2605028902541892, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.6375632436407168, 'reg_lambda': 0.5326442592312314, 'random_state': 196}. Best is trial 0 with value: 223.1582632716738.\n",
      "[I 2023-09-30 13:09:19,220] Trial 3 finished with value: 324.3885172581404 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.9062266645707984, 'n_estimators': 600, 'min_child_weight': 5, 'gamma': 0.3204649325443327, 'subsample': 0.75, 'colsample_bytree': 0.85, 'reg_alpha': 0.4945474088875045, 'reg_lambda': 0.5753942577243937, 'random_state': 592}. Best is trial 0 with value: 223.1582632716738.\n",
      "[I 2023-09-30 13:09:19,675] Trial 2 finished with value: 187.65976903393374 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 8, 'learning_rate': 0.01865443598282598, 'n_estimators': 689, 'min_child_weight': 4, 'gamma': 0.2907210433473007, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_alpha': 0.9186744956996298, 'reg_lambda': 0.6151767547850471, 'random_state': 967}. Best is trial 2 with value: 187.65976903393374.\n",
      "[I 2023-09-30 13:09:20,166] Trial 1 finished with value: 223.11289057269835 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 7, 'learning_rate': 0.45973464520909163, 'n_estimators': 830, 'min_child_weight': 7, 'gamma': 0.9945363336763692, 'subsample': 1.0, 'colsample_bytree': 0.85, 'reg_alpha': 0.633758069727806, 'reg_lambda': 0.4628556686300353, 'random_state': 400}. Best is trial 2 with value: 187.65976903393374.\n",
      "[I 2023-09-30 13:09:22,861] Trial 7 finished with value: 224.34754093808206 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 8, 'learning_rate': 0.5787384762584812, 'n_estimators': 538, 'min_child_weight': 2, 'gamma': 0.26378748942243957, 'subsample': 0.95, 'colsample_bytree': 1.0, 'reg_alpha': 0.01066462641131967, 'reg_lambda': 0.6993489734181777, 'random_state': 784}. Best is trial 2 with value: 187.65976903393374.\n",
      "[I 2023-09-30 13:09:23,158] Trial 8 finished with value: 215.77837915663295 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 10, 'learning_rate': 0.35325475683311724, 'n_estimators': 638, 'min_child_weight': 1, 'gamma': 0.4865346457027381, 'subsample': 0.75, 'colsample_bytree': 0.7, 'reg_alpha': 0.10180454692366704, 'reg_lambda': 0.6771810496658375, 'random_state': 427}. Best is trial 2 with value: 187.65976903393374.\n",
      "[I 2023-09-30 13:09:23,290] Trial 9 finished with value: 261.08972345267557 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'hist', 'max_depth': 4, 'learning_rate': 0.5589285082857341, 'n_estimators': 488, 'min_child_weight': 7, 'gamma': 0.3202368366590801, 'subsample': 0.6, 'colsample_bytree': 0.85, 'reg_alpha': 0.2915102858381857, 'reg_lambda': 0.3269706842872961, 'random_state': 725}. Best is trial 2 with value: 187.65976903393374.\n",
      "[I 2023-09-30 13:09:23,720] Trial 5 finished with value: 433.7685407540878 and parameters: {'objective': 'reg:squarederror', 'eval_metric': 'mae', 'tree_method': 'approx', 'max_depth': 10, 'learning_rate': 0.9253482573565023, 'n_estimators': 746, 'min_child_weight': 10, 'gamma': 0.5242932807649833, 'subsample': 0.6, 'colsample_bytree': 0.85, 'reg_alpha': 0.6376631382675254, 'reg_lambda': 0.3093518704313613, 'random_state': 575}. Best is trial 2 with value: 187.65976903393374.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.8843697816454247\n",
      "RMSE:  402.45292853211225\n",
      "graded! MAE:  187.65976903393374\n",
      "Best params: {\n",
      "    \"objective\": \"reg:squarederror\",\n",
      "    \"eval_metric\": \"mae\",\n",
      "    \"tree_method\": \"hist\",\n",
      "    \"max_depth\": 8,\n",
      "    \"learning_rate\": 0.01865443598282598,\n",
      "    \"n_estimators\": 689,\n",
      "    \"min_child_weight\": 4,\n",
      "    \"gamma\": 0.2907210433473007,\n",
      "    \"subsample\": 0.9,\n",
      "    \"colsample_bytree\": 0.6,\n",
      "    \"reg_alpha\": 0.9186744956996298,\n",
      "    \"reg_lambda\": 0.6151767547850471,\n",
      "    \"random_state\": 967\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_a = ModelTrainer().train_model(location=\"A\", trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
