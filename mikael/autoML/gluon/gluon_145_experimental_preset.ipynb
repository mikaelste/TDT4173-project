{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Henning skal teste å fjerne consecutives.</h3>\n",
    "<p> yee<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from pipeline_145_preset import Pipeline\n",
    "pipin = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PATH = f\"ag_145_experimental_preset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_0 = pipin.get_data(\"A\")\n",
    "df2_0 = pipin.get_data(\"B\")\n",
    "df3_0 = pipin.get_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_consecutive_measurments\n",
    "df1_0 = pipin.remove_consecutive_measurments(df1_0, 400, 25)\n",
    "df2_0 = pipin.remove_consecutive_measurments(df2_0, 400, 25)\n",
    "df3_0 = pipin.remove_consecutive_measurments(df3_0, 400, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>ceiling_height_agl:m</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>...</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>estimated</th>\n",
       "      <th>observed</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>hour</th>\n",
       "      <th>pv_measurement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22825</td>\n",
       "      <td>1728.949951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1728.949951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.299988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40386.476562</td>\n",
       "      <td>3.600</td>\n",
       "      <td>3.575</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.700</td>\n",
       "      <td>1.22350</td>\n",
       "      <td>1689.824951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1689.824951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.299988</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>33770.648438</td>\n",
       "      <td>3.350</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.875</td>\n",
       "      <td>1.21975</td>\n",
       "      <td>1563.224976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1563.224976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.649994</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13595.500000</td>\n",
       "      <td>3.050</td>\n",
       "      <td>2.950</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.425</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1283.425049</td>\n",
       "      <td>208.649994</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1283.425049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>281.674988</td>\n",
       "      <td>0.300</td>\n",
       "      <td>526.775024</td>\n",
       "      <td>...</td>\n",
       "      <td>2321.850098</td>\n",
       "      <td>2.725</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.950</td>\n",
       "      <td>1.21800</td>\n",
       "      <td>1003.500000</td>\n",
       "      <td>32468.150391</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1003.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.500000</td>\n",
       "      <td>11.975</td>\n",
       "      <td>22068.949219</td>\n",
       "      <td>...</td>\n",
       "      <td>11634.799805</td>\n",
       "      <td>2.550</td>\n",
       "      <td>2.350</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
       "0                     7.700              1.22825           1728.949951   \n",
       "1                     7.700              1.22350           1689.824951   \n",
       "2                     7.875              1.21975           1563.224976   \n",
       "3                     8.425              1.21800           1283.425049   \n",
       "4                     8.950              1.21800           1003.500000   \n",
       "\n",
       "   clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  \\\n",
       "0               0.000000             0.00       1728.949951              0.0   \n",
       "1               0.000000             0.00       1689.824951              0.0   \n",
       "2               0.000000             0.00       1563.224976              0.0   \n",
       "3             208.649994             0.75       1283.425049              0.0   \n",
       "4           32468.150391            23.10       1003.500000              0.0   \n",
       "\n",
       "   dew_point_2m:K  diffuse_rad:W  diffuse_rad_1h:J  ...  visibility:m  \\\n",
       "0      280.299988          0.000          0.000000  ...  40386.476562   \n",
       "1      280.299988          0.000          0.000000  ...  33770.648438   \n",
       "2      280.649994          0.000          0.000000  ...  13595.500000   \n",
       "3      281.674988          0.300        526.775024  ...   2321.850098   \n",
       "4      282.500000         11.975      22068.949219  ...  11634.799805   \n",
       "\n",
       "   wind_speed_10m:ms  wind_speed_u_10m:ms  wind_speed_v_10m:ms  \\\n",
       "0              3.600                3.575                0.500   \n",
       "1              3.350                3.350                0.275   \n",
       "2              3.050                2.950                0.750   \n",
       "3              2.725                2.600                0.875   \n",
       "4              2.550                2.350                0.925   \n",
       "\n",
       "   wind_speed_w_1000hPa:ms  estimated  observed  day_of_year  hour  \\\n",
       "0                      0.0        0.0       1.0        153.0  22.0   \n",
       "1                      0.0        0.0       1.0        153.0  23.0   \n",
       "2                      0.0        0.0       1.0        154.0   0.0   \n",
       "3                      0.0        0.0       1.0        154.0   1.0   \n",
       "4                      0.0        0.0       1.0        154.0   2.0   \n",
       "\n",
       "   pv_measurement  \n",
       "0            0.00  \n",
       "1            0.00  \n",
       "2            0.00  \n",
       "3            0.00  \n",
       "4           19.36  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = TabularDataset(df1_0)\n",
    "train2 = TabularDataset(df2_0)\n",
    "train3 = TabularDataset(df3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_145_experimental_presetA\"\n",
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_145_experimental_presetA\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   2.34 GB / 494.38 GB (0.5%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "Train Data Rows:    19853\n",
      "Train Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 1082.6485, 1358.08613)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6852.59 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.21 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.3s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.01 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'min_samples_leaf': 1, 'max_leaf_nodes': 15000, 'max_features': 0.5, 'ag_args': {'name_suffix': '_r19', 'priority': 20}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'min_samples_leaf': 5, 'max_leaf_nodes': 50000, 'max_features': 0.5, 'ag_args': {'name_suffix': '_r5', 'priority': 19}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7248284762542815, 'learning_rate': 0.07947286942946127, 'min_data_in_leaf': 50, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r158', 'priority': 18}}, {'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'learning_rate': 0.021720607471727896, 'min_data_in_leaf': 3, 'num_leaves': 21, 'ag_args': {'name_suffix': '_r118', 'priority': 17}}, {'extra_trees': True, 'feature_fraction': 0.7113010892989156, 'learning_rate': 0.012535427424259274, 'min_data_in_leaf': 16, 'num_leaves': 48, 'ag_args': {'name_suffix': '_r97', 'priority': 16}}, {'extra_trees': True, 'feature_fraction': 0.45555769907110816, 'learning_rate': 0.009591347321206594, 'min_data_in_leaf': 50, 'num_leaves': 110, 'ag_args': {'name_suffix': '_r71', 'priority': 15}}, {'extra_trees': False, 'feature_fraction': 0.40979710161022476, 'learning_rate': 0.008708890211023034, 'min_data_in_leaf': 3, 'num_leaves': 80, 'ag_args': {'name_suffix': '_r111', 'priority': 14}}],\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': [{}, {'bs': 1024, 'emb_drop': 0.6167722379778131, 'epochs': 44, 'layers': [200, 100, 50], 'lr': 0.053440377855629266, 'ps': 0.48477211305443607, 'ag_args': {'name_suffix': '_r25', 'priority': 13}}, {'bs': 1024, 'emb_drop': 0.6046989241462619, 'epochs': 48, 'layers': [200, 100, 50], 'lr': 0.00775309042164966, 'ps': 0.09244767444160731, 'ag_args': {'name_suffix': '_r51', 'priority': 12}}, {'bs': 512, 'emb_drop': 0.6557225316526186, 'epochs': 49, 'layers': [200, 100], 'lr': 0.023627682025564638, 'ps': 0.519566584552178, 'ag_args': {'name_suffix': '_r82', 'priority': 11}}, {'bs': 2048, 'emb_drop': 0.4066210919034579, 'epochs': 43, 'layers': [400, 200], 'lr': 0.0029598312717673434, 'ps': 0.4378695797438974, 'ag_args': {'name_suffix': '_r121', 'priority': 10}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': 9}}, {'bs': 128, 'emb_drop': 0.12106594798980945, 'epochs': 38, 'layers': [200, 100, 50], 'lr': 0.037991970245029975, 'ps': 0.33120008492595093, 'ag_args': {'name_suffix': '_r173', 'priority': 8}}, {'bs': 128, 'emb_drop': 0.4599138419358, 'epochs': 47, 'layers': [200, 100], 'lr': 0.03888383281136287, 'ps': 0.28193673177122863, 'ag_args': {'name_suffix': '_r128', 'priority': 7}}],\n",
      "\t'CAT': [{}, {'depth': 5, 'l2_leaf_reg': 4.774992314058497, 'learning_rate': 0.038551267822920274, 'ag_args': {'name_suffix': '_r16', 'priority': 6}}, {'depth': 4, 'l2_leaf_reg': 1.9950125740798321, 'learning_rate': 0.028091050379971633, 'ag_args': {'name_suffix': '_r42', 'priority': 5}}, {'depth': 6, 'l2_leaf_reg': 1.8298803017644376, 'learning_rate': 0.017844259810823604, 'ag_args': {'name_suffix': '_r93', 'priority': 4}}, {'depth': 7, 'l2_leaf_reg': 4.81099604606794, 'learning_rate': 0.019085060180573103, 'ag_args': {'name_suffix': '_r44', 'priority': 3}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 29 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-453.8266\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-455.2582\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-258.4436\t = Validation score   (-mean_absolute_error)\n",
      "\t42.04s\t = Training   runtime\n",
      "\t84.9s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-271.7405\t = Validation score   (-mean_absolute_error)\n",
      "\t69.16s\t = Training   runtime\n",
      "\t82.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-309.7828\t = Validation score   (-mean_absolute_error)\n",
      "\t66.05s\t = Training   runtime\n",
      "\t1.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-277.5229\t = Validation score   (-mean_absolute_error)\n",
      "\t463.11s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-309.8548\t = Validation score   (-mean_absolute_error)\n",
      "\t9.02s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-306.6593\t = Validation score   (-mean_absolute_error)\n",
      "\t33.13s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-287.4556\t = Validation score   (-mean_absolute_error)\n",
      "\t244.35s\t = Training   runtime\n",
      "\t30.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-293.3246\t = Validation score   (-mean_absolute_error)\n",
      "\t105.42s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r19_BAG_L1 ...\n",
      "\t-309.747\t = Validation score   (-mean_absolute_error)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitting model: RandomForest_r5_BAG_L1 ...\n",
      "\t-310.8036\t = Validation score   (-mean_absolute_error)\n",
      "\t17.56s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_r158_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-277.1403\t = Validation score   (-mean_absolute_error)\n",
      "\t123.45s\t = Training   runtime\n",
      "\t111.53s\t = Validation runtime\n",
      "Fitting model: LightGBM_r118_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-263.344\t = Validation score   (-mean_absolute_error)\n",
      "\t32.13s\t = Training   runtime\n",
      "\t35.45s\t = Validation runtime\n",
      "Fitting model: LightGBM_r97_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-262.3061\t = Validation score   (-mean_absolute_error)\n",
      "\t48.48s\t = Training   runtime\n",
      "\t93.62s\t = Validation runtime\n",
      "Fitting model: LightGBM_r71_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-272.9282\t = Validation score   (-mean_absolute_error)\n",
      "\t84.49s\t = Training   runtime\n",
      "\t304.68s\t = Validation runtime\n",
      "Fitting model: LightGBM_r111_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-265.5109\t = Validation score   (-mean_absolute_error)\n",
      "\t83.64s\t = Training   runtime\n",
      "\t215.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r25_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-320.2618\t = Validation score   (-mean_absolute_error)\n",
      "\t29.85s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r51_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-290.2023\t = Validation score   (-mean_absolute_error)\n",
      "\t31.69s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r82_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-319.4699\t = Validation score   (-mean_absolute_error)\n",
      "\t34.99s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r121_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-333.2936\t = Validation score   (-mean_absolute_error)\n",
      "\t46.55s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-302.9097\t = Validation score   (-mean_absolute_error)\n",
      "\t109.27s\t = Training   runtime\n",
      "\t1.98s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r173_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-315.6956\t = Validation score   (-mean_absolute_error)\n",
      "\t86.85s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r128_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-325.5033\t = Validation score   (-mean_absolute_error)\n",
      "\t117.33s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_r16_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-285.7887\t = Validation score   (-mean_absolute_error)\n",
      "\t532.68s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_r42_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-296.8803\t = Validation score   (-mean_absolute_error)\n",
      "\t447.51s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_r93_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-282.4977\t = Validation score   (-mean_absolute_error)\n",
      "\t552.77s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_r44_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-276.4676\t = Validation score   (-mean_absolute_error)\n",
      "\t717.14s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-269.0078\t = Validation score   (-mean_absolute_error)\n",
      "\t458.59s\t = Training   runtime\n",
      "\t603.63s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-254.8129\t = Validation score   (-mean_absolute_error)\n",
      "\t2.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 27 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-254.0177\t = Validation score   (-mean_absolute_error)\n",
      "\t26.37s\t = Training   runtime\n",
      "\t2.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.8379\t = Validation score   (-mean_absolute_error)\n",
      "\t21.94s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-250.4734\t = Validation score   (-mean_absolute_error)\n",
      "\t263.69s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-252.2129\t = Validation score   (-mean_absolute_error)\n",
      "\t64.35s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-249.839\t = Validation score   (-mean_absolute_error)\n",
      "\t28.08s\t = Training   runtime\n",
      "\t1.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-248.1002\t = Validation score   (-mean_absolute_error)\n",
      "\t59.29s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.5664\t = Validation score   (-mean_absolute_error)\n",
      "\t21.6s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-249.1143\t = Validation score   (-mean_absolute_error)\n",
      "\t89.1s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_r19_BAG_L2 ...\n",
      "\t-250.217\t = Validation score   (-mean_absolute_error)\n",
      "\t12.44s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: RandomForest_r5_BAG_L2 ...\n",
      "\t-248.2389\t = Validation score   (-mean_absolute_error)\n",
      "\t50.2s\t = Training   runtime\n",
      "\t0.86s\t = Validation runtime\n",
      "Fitting model: LightGBM_r158_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-255.0194\t = Validation score   (-mean_absolute_error)\n",
      "\t16.18s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_r118_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-252.617\t = Validation score   (-mean_absolute_error)\n",
      "\t22.7s\t = Training   runtime\n",
      "\t2.66s\t = Validation runtime\n",
      "Fitting model: LightGBM_r97_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-255.3365\t = Validation score   (-mean_absolute_error)\n",
      "\t27.71s\t = Training   runtime\n",
      "\t6.87s\t = Validation runtime\n",
      "Fitting model: LightGBM_r71_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-256.2502\t = Validation score   (-mean_absolute_error)\n",
      "\t55.74s\t = Training   runtime\n",
      "\t18.5s\t = Validation runtime\n",
      "Fitting model: LightGBM_r111_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.4359\t = Validation score   (-mean_absolute_error)\n",
      "\t49.03s\t = Training   runtime\n",
      "\t6.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r25_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.1349\t = Validation score   (-mean_absolute_error)\n",
      "\t52.14s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r51_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-253.2979\t = Validation score   (-mean_absolute_error)\n",
      "\t61.28s\t = Training   runtime\n",
      "\t1.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r82_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-248.342\t = Validation score   (-mean_absolute_error)\n",
      "\t70.22s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r121_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-255.5416\t = Validation score   (-mean_absolute_error)\n",
      "\t73.45s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r145_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-247.9728\t = Validation score   (-mean_absolute_error)\n",
      "\t133.03s\t = Training   runtime\n",
      "\t1.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r173_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-252.413\t = Validation score   (-mean_absolute_error)\n",
      "\t83.24s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r128_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-258.6424\t = Validation score   (-mean_absolute_error)\n",
      "\t99.68s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: CatBoost_r16_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-252.0847\t = Validation score   (-mean_absolute_error)\n",
      "\t68.85s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_r42_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.9252\t = Validation score   (-mean_absolute_error)\n",
      "\t62.27s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: CatBoost_r93_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.1847\t = Validation score   (-mean_absolute_error)\n",
      "\t129.88s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_r44_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-251.5873\t = Validation score   (-mean_absolute_error)\n",
      "\t298.87s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-252.9898\t = Validation score   (-mean_absolute_error)\n",
      "\t39.38s\t = Training   runtime\n",
      "\t2.65s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-243.6387\t = Validation score   (-mean_absolute_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7040.85s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"ag_145_experimental_presetA\")\n"
     ]
    }
   ],
   "source": [
    "predictor1 = TabularPredictor(label=\"pv_measurement\",\n",
    "                              eval_metric='mean_absolute_error',\n",
    "                              path= DEFAULT_PATH+\"A\"\n",
    "                              ).fit(\n",
    "    train1,\n",
    "    time_limit=3600,\n",
    "    # hyperparameters='extrme', \n",
    "    presets='experimental_zeroshot_hpo_hybrid', \n",
    "    # tuning_data = tuning1,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"ag_145_experimental_presetB\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   216.24 GB / 494.38 GB (43.7%)\n",
      "Train Data Rows:    13632\n",
      "Train Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, 0.0, 203.67563, 257.36859)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/miksx/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4401.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.89 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.4s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.75 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.53s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'min_samples_leaf': 1, 'max_leaf_nodes': 15000, 'max_features': 0.5, 'ag_args': {'name_suffix': '_r19', 'priority': 20}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}, {'min_samples_leaf': 5, 'max_leaf_nodes': 50000, 'max_features': 0.5, 'ag_args': {'name_suffix': '_r5', 'priority': 19}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge', {'extra_trees': False, 'feature_fraction': 0.7248284762542815, 'learning_rate': 0.07947286942946127, 'min_data_in_leaf': 50, 'num_leaves': 89, 'ag_args': {'name_suffix': '_r158', 'priority': 18}}, {'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'learning_rate': 0.021720607471727896, 'min_data_in_leaf': 3, 'num_leaves': 21, 'ag_args': {'name_suffix': '_r118', 'priority': 17}}, {'extra_trees': True, 'feature_fraction': 0.7113010892989156, 'learning_rate': 0.012535427424259274, 'min_data_in_leaf': 16, 'num_leaves': 48, 'ag_args': {'name_suffix': '_r97', 'priority': 16}}, {'extra_trees': True, 'feature_fraction': 0.45555769907110816, 'learning_rate': 0.009591347321206594, 'min_data_in_leaf': 50, 'num_leaves': 110, 'ag_args': {'name_suffix': '_r71', 'priority': 15}}, {'extra_trees': False, 'feature_fraction': 0.40979710161022476, 'learning_rate': 0.008708890211023034, 'min_data_in_leaf': 3, 'num_leaves': 80, 'ag_args': {'name_suffix': '_r111', 'priority': 14}}],\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': [{}, {'bs': 1024, 'emb_drop': 0.6167722379778131, 'epochs': 44, 'layers': [200, 100, 50], 'lr': 0.053440377855629266, 'ps': 0.48477211305443607, 'ag_args': {'name_suffix': '_r25', 'priority': 13}}, {'bs': 1024, 'emb_drop': 0.6046989241462619, 'epochs': 48, 'layers': [200, 100, 50], 'lr': 0.00775309042164966, 'ps': 0.09244767444160731, 'ag_args': {'name_suffix': '_r51', 'priority': 12}}, {'bs': 512, 'emb_drop': 0.6557225316526186, 'epochs': 49, 'layers': [200, 100], 'lr': 0.023627682025564638, 'ps': 0.519566584552178, 'ag_args': {'name_suffix': '_r82', 'priority': 11}}, {'bs': 2048, 'emb_drop': 0.4066210919034579, 'epochs': 43, 'layers': [400, 200], 'lr': 0.0029598312717673434, 'ps': 0.4378695797438974, 'ag_args': {'name_suffix': '_r121', 'priority': 10}}, {'bs': 128, 'emb_drop': 0.44339037504795686, 'epochs': 31, 'layers': [400, 200, 100], 'lr': 0.008615195908919904, 'ps': 0.19220253419114286, 'ag_args': {'name_suffix': '_r145', 'priority': 9}}, {'bs': 128, 'emb_drop': 0.12106594798980945, 'epochs': 38, 'layers': [200, 100, 50], 'lr': 0.037991970245029975, 'ps': 0.33120008492595093, 'ag_args': {'name_suffix': '_r173', 'priority': 8}}, {'bs': 128, 'emb_drop': 0.4599138419358, 'epochs': 47, 'layers': [200, 100], 'lr': 0.03888383281136287, 'ps': 0.28193673177122863, 'ag_args': {'name_suffix': '_r128', 'priority': 7}}],\n",
      "\t'CAT': [{}, {'depth': 5, 'l2_leaf_reg': 4.774992314058497, 'learning_rate': 0.038551267822920274, 'ag_args': {'name_suffix': '_r16', 'priority': 6}}, {'depth': 4, 'l2_leaf_reg': 1.9950125740798321, 'learning_rate': 0.028091050379971633, 'ag_args': {'name_suffix': '_r42', 'priority': 5}}, {'depth': 6, 'l2_leaf_reg': 1.8298803017644376, 'learning_rate': 0.017844259810823604, 'ag_args': {'name_suffix': '_r93', 'priority': 4}}, {'depth': 7, 'l2_leaf_reg': 4.81099604606794, 'learning_rate': 0.019085060180573103, 'ag_args': {'name_suffix': '_r44', 'priority': 3}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 29 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-77.0431\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-77.2804\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-41.1818\t = Validation score   (-mean_absolute_error)\n",
      "\t68.6s\t = Training   runtime\n",
      "\t76.91s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-44.0708\t = Validation score   (-mean_absolute_error)\n",
      "\t162.84s\t = Training   runtime\n",
      "\t75.61s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-49.9611\t = Validation score   (-mean_absolute_error)\n",
      "\t37.52s\t = Training   runtime\n",
      "\t0.75s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-44.2848\t = Validation score   (-mean_absolute_error)\n",
      "\t308.07s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-49.71\t = Validation score   (-mean_absolute_error)\n",
      "\t11.63s\t = Training   runtime\n",
      "\t0.79s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-48.7705\t = Validation score   (-mean_absolute_error)\n",
      "\t55.83s\t = Training   runtime\n",
      "\t0.98s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictor2 \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                               eval_metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                               path\u001b[39m=\u001b[39;49m DEFAULT_PATH\u001b[39m+\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mB\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                               )\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train2,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# time_limit=6000,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# hyperparameters='extrme', \u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     presets\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mexperimental_zeroshot_hpo_hybrid\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# tuning_data = tuning1,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# use_bag_holdout=True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# num_bag_folds= 6,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m# refit_full = True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# auto_stack = True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# num_bag_sets= 10,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# set_best_to_refit_full= True,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# num_stack_levels = 2,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# verbosity = 3\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/miksx/GitHub/Forest-Gump/mikael/autoML/gluon/gluon_145_experimental_preset.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:986\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mfit_weighted_ensemble\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39m# Save predictor to disk to enable prediction and training after interrupt\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    987\u001b[0m     X\u001b[39m=\u001b[39;49mtrain_data,\n\u001b[1;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39;49mtuning_data,\n\u001b[1;32m    989\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49munlabeled_data,\n\u001b[1;32m    990\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    991\u001b[0m     num_bag_folds\u001b[39m=\u001b[39;49mnum_bag_folds,\n\u001b[1;32m    992\u001b[0m     num_bag_sets\u001b[39m=\u001b[39;49mnum_bag_sets,\n\u001b[1;32m    993\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    994\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    995\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    996\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    997\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    998\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    999\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m   1000\u001b[0m     verbosity\u001b[39m=\u001b[39;49mverbosity,\n\u001b[1;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39;49muse_bag_holdout,\n\u001b[1;32m   1002\u001b[0m )\n\u001b[1;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[1;32m   1005\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_post_fit(\n\u001b[1;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mkeep_only_best\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39mkwargs[\u001b[39m\"\u001b[39m\u001b[39mrefit_full\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39minfer_limit,\n\u001b[1;32m   1013\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:159\u001b[0m, in \u001b[0;36mAbstractTabularLearner.fit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLearner is already fit.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_input(X\u001b[39m=\u001b[39mX, X_val\u001b[39m=\u001b[39mX_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, X_val\u001b[39m=\u001b[39;49mX_val, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/learner/default_learner.py:157\u001b[0m, in \u001b[0;36mDefaultLearner._fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_metric \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39meval_metric\n\u001b[1;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[0;32m--> 157\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    158\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    159\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    160\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    161\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    162\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    163\u001b[0m     holdout_frac\u001b[39m=\u001b[39;49mholdout_frac,\n\u001b[1;32m    164\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit_trainer,\n\u001b[1;32m    165\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    166\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    167\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    168\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrainer_fit_kwargs,\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_trainer(trainer\u001b[39m=\u001b[39mtrainer)\n\u001b[1;32m    171\u001b[0m time_end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/tabular/trainer/auto_trainer.py:114\u001b[0m, in \u001b[0;36mAutoTrainer.fit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m log_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, log_str)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_and_ensemble(\n\u001b[1;32m    115\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    116\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    117\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    118\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    119\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    120\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    121\u001b[0m     num_stack_levels\u001b[39m=\u001b[39;49mnum_stack_levels,\n\u001b[1;32m    122\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m    123\u001b[0m     core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs,\n\u001b[1;32m    124\u001b[0m     aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs,\n\u001b[1;32m    125\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    126\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    127\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    128\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2419\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_rows_val \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(X_val)\n\u001b[1;32m   2418\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_cols_train \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mlist\u001b[39m(X\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m-> 2419\u001b[0m model_names_fit \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_multi_levels(\n\u001b[1;32m   2420\u001b[0m     X,\n\u001b[1;32m   2421\u001b[0m     y,\n\u001b[1;32m   2422\u001b[0m     hyperparameters\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m   2423\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2424\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2425\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2426\u001b[0m     level_start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2427\u001b[0m     level_end\u001b[39m=\u001b[39;49mnum_stack_levels \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2428\u001b[0m     time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2429\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2430\u001b[0m )\n\u001b[1;32m   2431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_model_names()) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2432\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAutoGluon did not successfully train any models\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:383\u001b[0m, in \u001b[0;36mAbstractTrainer.train_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    381\u001b[0m         core_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_core)\n\u001b[1;32m    382\u001b[0m         aux_kwargs_level[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs_level\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m, time_limit_aux)\n\u001b[0;32m--> 383\u001b[0m     base_model_names, aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level(\n\u001b[1;32m    384\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    385\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    386\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    387\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    388\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    389\u001b[0m         models\u001b[39m=\u001b[39;49mhyperparameters,\n\u001b[1;32m    390\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    391\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    392\u001b[0m         core_kwargs\u001b[39m=\u001b[39;49mcore_kwargs_level,\n\u001b[1;32m    393\u001b[0m         aux_kwargs\u001b[39m=\u001b[39;49maux_kwargs_level,\n\u001b[1;32m    394\u001b[0m         name_suffix\u001b[39m=\u001b[39;49mname_suffix,\n\u001b[1;32m    395\u001b[0m         infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    396\u001b[0m         infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    397\u001b[0m     )\n\u001b[1;32m    398\u001b[0m     model_names_fit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m base_model_names \u001b[39m+\u001b[39m aux_models\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_best \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(model_names_fit) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:527\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    525\u001b[0m     core_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m core_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[1;32m    526\u001b[0m     aux_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m aux_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m name_suffix\n\u001b[0;32m--> 527\u001b[0m core_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[1;32m    528\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    529\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    530\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    531\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    532\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    533\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    534\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    535\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m    536\u001b[0m     infer_limit_batch_size\u001b[39m=\u001b[39;49minfer_limit_batch_size,\n\u001b[1;32m    537\u001b[0m     base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m    538\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcore_kwargs,\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    541\u001b[0m \u001b[39mif\u001b[39;00m X_val \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m     aux_models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_new_level_aux(\n\u001b[1;32m    543\u001b[0m         X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, base_model_names\u001b[39m=\u001b[39mcore_models, level\u001b[39m=\u001b[39mlevel \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, infer_limit\u001b[39m=\u001b[39minfer_limit, infer_limit_batch_size\u001b[39m=\u001b[39minfer_limit_batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39maux_kwargs\n\u001b[1;32m    544\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:661\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    660\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[1;32m    662\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[1;32m    663\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    664\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    665\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    666\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    667\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    668\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    669\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m    670\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m    671\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m    672\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    673\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2369\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2367\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2368\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 2369\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[1;32m   2370\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2371\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2372\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2373\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2374\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[1;32m   2375\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2376\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[1;32m   2377\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2378\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2379\u001b[0m     )\n\u001b[1;32m   2380\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[1;32m   2381\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2218\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2217\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 2218\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[1;32m   2219\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2220\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2221\u001b[0m         k_fold_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2222\u001b[0m         k_fold_end\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2223\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m   2224\u001b[0m         n_repeat_start\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2225\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2226\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[1;32m   2227\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[1;32m   2228\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[1;32m   2229\u001b[0m     )\n\u001b[1;32m   2231\u001b[0m multi_fold_time_elapsed \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m multi_fold_time_start\n\u001b[1;32m   2232\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2326\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2324\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2325\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[0;32m-> 2326\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[1;32m   2327\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   2328\u001b[0m )\n\u001b[1;32m   2330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m   2331\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:2099\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   2095\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[1;32m   2096\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[1;32m   2097\u001b[0m         )\n\u001b[1;32m   2098\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[0;32m-> 2099\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_and_save(\n\u001b[1;32m   2100\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2101\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2102\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   2103\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2104\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2105\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2106\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m   2107\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   2108\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m   2109\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[1;32m   2110\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[1;32m   2111\u001b[0m     )\n\u001b[1;32m   2112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m   2113\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:1761\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1759\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[1;32m   1760\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1761\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1763\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1764\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:1712\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[1;32m   1708\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1709\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1712\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1713\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py:838\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    837\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    840\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:165\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[0;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, time_limit\u001b[39m=\u001b[39;49mtime_limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:266\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[0;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[39m# Reserve time for final refit model\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtime_limit\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m*\u001b[39m folds_to_fit \u001b[39m/\u001b[39m (folds_to_fit \u001b[39m+\u001b[39m \u001b[39m1.2\u001b[39m)\n\u001b[0;32m--> 266\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_folds(\n\u001b[1;32m    267\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    268\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    269\u001b[0m     model_base\u001b[39m=\u001b[39;49mmodel_base,\n\u001b[1;32m    270\u001b[0m     X_pseudo\u001b[39m=\u001b[39;49mX_pseudo,\n\u001b[1;32m    271\u001b[0m     y_pseudo\u001b[39m=\u001b[39;49my_pseudo,\n\u001b[1;32m    272\u001b[0m     k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m    273\u001b[0m     k_fold_start\u001b[39m=\u001b[39;49mk_fold_start,\n\u001b[1;32m    274\u001b[0m     k_fold_end\u001b[39m=\u001b[39;49mk_fold_end,\n\u001b[1;32m    275\u001b[0m     n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m    276\u001b[0m     n_repeat_start\u001b[39m=\u001b[39;49mn_repeat_start,\n\u001b[1;32m    277\u001b[0m     save_folds\u001b[39m=\u001b[39;49msave_bag_folds,\n\u001b[1;32m    278\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    279\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39m# FIXME: Cleanup self\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[39m# FIXME: Support `can_refit_full=False` models\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m refit_folds:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:592\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_folds\u001b[0;34m(self, X, y, model_base, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, time_limit, sample_weight, save_folds, groups, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[39mfor\u001b[39;00m fold_fit_args \u001b[39min\u001b[39;00m fold_fit_args_list:\n\u001b[1;32m    591\u001b[0m     fold_fitting_strategy\u001b[39m.\u001b[39mschedule_fold_model_fit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_fit_args)\n\u001b[0;32m--> 592\u001b[0m fold_fitting_strategy\u001b[39m.\u001b[39;49mafter_all_folds_scheduled()\n\u001b[1;32m    594\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m    595\u001b[0m     \u001b[39m# No need to add child times or save child here as this already occurred in the fold_fitting_strategy\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_child(model\u001b[39m=\u001b[39mmodel, add_child_times\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py:538\u001b[0m, in \u001b[0;36mParallelFoldFittingStrategy.after_all_folds_scheduled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m unfinished \u001b[39m=\u001b[39m job_refs\n\u001b[1;32m    537\u001b[0m \u001b[39mwhile\u001b[39;00m unfinished:\n\u001b[0;32m--> 538\u001b[0m     finished, unfinished \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mray\u001b[39m.\u001b[39;49mwait(unfinished, num_returns\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    539\u001b[0m     finished \u001b[39m=\u001b[39m finished[\u001b[39m0\u001b[39m]\n\u001b[1;32m    540\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     23\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/TDT4173/lib/python3.10/site-packages/ray/_private/worker.py:2732\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2730\u001b[0m timeout \u001b[39m=\u001b[39m timeout \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m10\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m6\u001b[39m\n\u001b[1;32m   2731\u001b[0m timeout_milliseconds \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m)\n\u001b[0;32m-> 2732\u001b[0m ready_ids, remaining_ids \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mwait(\n\u001b[1;32m   2733\u001b[0m     object_refs,\n\u001b[1;32m   2734\u001b[0m     num_returns,\n\u001b[1;32m   2735\u001b[0m     timeout_milliseconds,\n\u001b[1;32m   2736\u001b[0m     worker\u001b[39m.\u001b[39;49mcurrent_task_id,\n\u001b[1;32m   2737\u001b[0m     fetch_local,\n\u001b[1;32m   2738\u001b[0m )\n\u001b[1;32m   2739\u001b[0m \u001b[39mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:3012\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:400\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor2 = TabularPredictor(label=\"pv_measurement\",\n",
    "                              eval_metric='mean_absolute_error',\n",
    "                              path= DEFAULT_PATH+\"B\"\n",
    "                              ).fit(\n",
    "    train2,\n",
    "    time_limit=3600,\n",
    "    # hyperparameters='extrme', \n",
    "    presets='experimental_zeroshot_hpo_hybrid', \n",
    "    # tuning_data = tuning1,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )\n",
    "\n",
    "# tuning_data\n",
    "# num bag holdout 6\n",
    "# bag_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20231107_001926/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20231107_001926/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   655.49 GB / 994.66 GB (65.9%)\n",
      "Train Data Rows:    26095\n",
      "Train Data Columns: 49\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 77.63106, 165.81688)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    12692.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.53 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['snow_drift:idx']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['snow_drift:idx']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 48 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 46 | ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['elevation:m', 'snow_density:kgm3']\n",
      "\t0.5s = Fit runtime\n",
      "\t48 features in original data used to generate 48 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.67s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-29.1151\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t1.76s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-29.0905\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.4497\t = Validation score   (-mean_absolute_error)\n",
      "\t90.88s\t = Training   runtime\n",
      "\t93.55s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.346\t = Validation score   (-mean_absolute_error)\n",
      "\t127.96s\t = Training   runtime\n",
      "\t214.89s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-19.7427\t = Validation score   (-mean_absolute_error)\n",
      "\t35.43s\t = Training   runtime\n",
      "\t1.27s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.9658\t = Validation score   (-mean_absolute_error)\n",
      "\t821.54s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-19.7181\t = Validation score   (-mean_absolute_error)\n",
      "\t7.03s\t = Training   runtime\n",
      "\t1.69s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.2476\t = Validation score   (-mean_absolute_error)\n",
      "\t58.27s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.43\t = Validation score   (-mean_absolute_error)\n",
      "\t388.65s\t = Training   runtime\n",
      "\t204.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.9975\t = Validation score   (-mean_absolute_error)\n",
      "\t231.24s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-17.0576\t = Validation score   (-mean_absolute_error)\n",
      "\t313.34s\t = Training   runtime\n",
      "\t403.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-16.017\t = Validation score   (-mean_absolute_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.5143\t = Validation score   (-mean_absolute_error)\n",
      "\t8.75s\t = Training   runtime\n",
      "\t1.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.2631\t = Validation score   (-mean_absolute_error)\n",
      "\t7.04s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-15.8638\t = Validation score   (-mean_absolute_error)\n",
      "\t56.93s\t = Training   runtime\n",
      "\t2.01s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.4443\t = Validation score   (-mean_absolute_error)\n",
      "\t32.38s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-15.8232\t = Validation score   (-mean_absolute_error)\n",
      "\t9.56s\t = Training   runtime\n",
      "\t2.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.0857\t = Validation score   (-mean_absolute_error)\n",
      "\t60.7s\t = Training   runtime\n",
      "\t1.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.1754\t = Validation score   (-mean_absolute_error)\n",
      "\t9.11s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.2449\t = Validation score   (-mean_absolute_error)\n",
      "\t85.91s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-16.3502\t = Validation score   (-mean_absolute_error)\n",
      "\t45.31s\t = Training   runtime\n",
      "\t1.92s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-15.6089\t = Validation score   (-mean_absolute_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2647.99s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20231107_001926/\")\n"
     ]
    }
   ],
   "source": [
    "predictor3 = TabularPredictor(label=\"pv_measurement\",\n",
    "                              eval_metric='mean_absolute_error',\n",
    "                              path= DEFAULT_PATH+\"C\"\n",
    "                              ).fit(\n",
    "    train3,\n",
    "    time_limit=3600,\n",
    "    # hyperparameters='extrme', \n",
    "    presets='experimental_zeroshot_hpo_hybrid', \n",
    "    # tuning_data = tuning1,\n",
    "    # use_bag_holdout=True,\n",
    "    # num_bag_folds= 6,\n",
    "    # refit_full = True,\n",
    "    # auto_stack = True,\n",
    "    # num_bag_sets= 10,\n",
    "    # set_best_to_refit_full= True,\n",
    "    # num_stack_levels = 2,\n",
    "    # verbosity = 3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pipin.get_test_data(\"A\")\n",
    "test2 = pipin.get_test_data(\"B\")\n",
    "test3 = pipin.get_test_data(\"C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data1 = TabularDataset(test1)\n",
    "test_data2 = TabularDataset(test2)\n",
    "test_data3 = TabularDataset(test3)\n",
    "\n",
    "pred1 = pd.DataFrame(predictor1.predict(test_data1))\n",
    "pred2 = pd.DataFrame(predictor2.predict(test_data2))\n",
    "pred3 = pd.DataFrame(predictor3.predict(test_data3))\n",
    "\n",
    "negatives_pred1 = pred1[pred1[\"pv_measurement\"] < 0]\n",
    "negatives_pred2 = pred2[pred2[\"pv_measurement\"] < 0]\n",
    "negatives_pred3 = pred3[pred3[\"pv_measurement\"] < 0]\n",
    "neg = pd.concat([negatives_pred1, negatives_pred2, negatives_pred3])\n",
    "neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.concat([pred1, pred2, pred3])\n",
    "final_prediction = pipin.post_processing(pred, prediction_column=\"pv_measurement\")\n",
    "final_prediction.to_csv('gluon_145_experimental_preset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.67033104400012"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = pipin.compare_mae(final_prediction)\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.evaluate(df1, silent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
